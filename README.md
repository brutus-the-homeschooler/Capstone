
# American Community Survey (ACS) Data Processing and Analysis Project

## Overview
This project automates the process of collecting, processing, and analyzing data from the [American Community Survey](https://www.census.gov/programs-surveys/acs/data/summary-file.html) (ACS) 1-Year Supplemental Estimates for 2022. The processed data is stored in a structured format within a SQLite database, organized into three primary tables:

- **`census_data`**: Contains ACS variables and measurements of error for various geographic locations.
- **`place_dictionary`**: Maps place names to their corresponding FIPS codes.
- **`state_dictionary`**: Maps state names to their corresponding FIPS codes.

## Project Structure

```
/
|-- .github/
|    |-- workflows/
|         |-- ACS_Scrape.yml  # GitHub Actions workflow file
|
|-- Database/
|    |-- acsse_2022.db  # SQLite database file containing three tables
|    |-- README.md  # Information about the database and its usage
|-- Dictionary/
|    |-- Place Dictionary.csv  # Place-related metadata
|    |-- State Dictionary.csv  # State-related metadata
|    |-- Variable Dictionary.csv  # Metadata for ACS variables
|    |-- README.md  # Information about the dictionaries and CSV files
|
|-- Scripts/
|    |-- fetch_and_save.py  # Python script to fetch ACS data and save to SQLite
|
|-- Data/
|   
|
|-- variables.csv  # List of variables to query from the ACS API WILL BE DEPRECATED
|-- City of Dublin American Community Survey Dictionary.xlsx  # Additional data or documentation File contains all dictionaries and methodology for variables
```

## How to Use

### 1. Data Collection & Processing
The data processing workflow is automated using a GitHub Actions workflow (`ACS_Scrape.yml`). The workflow:

- Fetches data from the ACS API based on specified variables.
- Processes the data and structures it into a SQLite database (`acsse_2022.db`).
- Pushes the updated database back to the repository.

To manually trigger the workflow or view its status, go to the "Actions" tab of this repository.

### 2. Connecting to the SQLite Database
The main SQLite database (`acsse_2022.db`) contains three tables: `census_data`, `place_dictionary`, and `state_dictionary`. You can connect to and query these tables using Python or R.

**Python Example**

```python
import sqlite3
import pandas as pd

# Connect to the SQLite database
conn = sqlite3.connect('Database/acsse_2022.db')

# Query a table
census_data_df = pd.read_sql_query("SELECT * FROM census_data", conn)

# Close the connection
conn.close()
```

**R Example**

```r
install.packages("DBI")
install.packages("RSQLite")

library(DBI)
library(RSQLite)

# Connect to the SQLite database
con <- dbConnect(RSQLite::SQLite(), "Database/acsse_2022.db")

# Query a table
census_data_df <- dbReadTable(con, "census_data")

# Close the connection
dbDisconnect(con)
```

## Getting Started

### Requirements
- **Python 3.x**: The data-fetching and processing scripts are written in Python.
- **SQLite**: The processed data is stored in a SQLite database.
- **GitHub Actions**: Used for automation; workflows are defined in `.github/workflows/ACS_Scrape.yml`.

### Python Dependencies
To run the Python scripts, install the necessary dependencies:

```bash
pip install pandas requests
```

### GitHub Secrets and Environment Variables
- **`CENSUS_API_KEY`**: Your Census API key, used to authenticate requests to the ACS API.
- **`PERSONAL_ACCESS_TOKEN`**: A GitHub personal access token, used by GitHub Actions to commit and push changes to the repository.

## Data Sources

### ACS API Data
The `census_data` table is generated by querying the ACS API for variables specified in `Variable Dictionary.csv`. Each variable has its corresponding Measurement of Error (MOE) included.

### Place and State Dictionaries
The `place_dictionary` and `state_dictionary` tables are derived from CSV files in the `Database/Dictionary/` folder, providing additional metadata for places and states, such as FIPS codes and names.

## Folder Structure Details

- **`.github/workflows/`**  
  Contains the GitHub Actions workflow configuration file (`ACS_Scrape.yml`), which automates data fetching and processing.

- **`Database/`**  
  Contains the SQLite database file (`acsse_2022.db`) and related dictionaries in CSV format. Each CSV has a corresponding README file explaining its purpose.

- **`Scripts/`**  
  Contains Python scripts used to fetch and process data from the ACS API.

- **`Data/`**  
  Stores raw and processed data files. This folder can be used for staging data before loading it into the database.

## Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository.
2. Create a new branch:
    ```bash
    git checkout -b feature-branch
    ```
3. Make your changes and commit them:
    ```bash
    git commit -am 'Add new feature'
    ```
4. Push to the branch:
    ```bash
    git push origin feature-branch
    ```
5. Create a new Pull Request.

## License
This project is licensed under the MIT License - see the `LICENSE` file for details.

## Notes
- The `acsse_2022.db` SQLite file should be used as the main source of data for analysis.
- Ensure that all necessary secrets are properly set up in the GitHub repository to allow for successful automation.
